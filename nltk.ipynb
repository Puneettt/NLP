{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb902db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e723a999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eighty',\n",
       " 'seven',\n",
       " 'miles',\n",
       " 'played',\n",
       " 'to',\n",
       " 'go',\n",
       " 'yet',\n",
       " '78mmb',\n",
       " 'zk19900',\n",
       " 'Onward']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize('Eighty-seven miles played to go, yet. 78mmb, zk19900,,,...... Onward!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93163c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a80afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d71857cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am not doing .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'I am not doing . '\n",
    "data.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f4c6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'brazil',\n",
       " 'they',\n",
       " 'drive',\n",
       " 'on',\n",
       " 'the',\n",
       " 'right-hand',\n",
       " 'side',\n",
       " 'of',\n",
       " 'the',\n",
       " 'road',\n",
       " '.',\n",
       " 'brazil',\n",
       " 'has',\n",
       " 'a',\n",
       " 'large',\n",
       " 'coastline',\n",
       " 'on',\n",
       " 'the',\n",
       " 'eastern',\n",
       " 'side',\n",
       " 'of',\n",
       " 'south',\n",
       " 'america']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"In Brazil they drive on the right-hand side of the road. Brazil has a large coastline on the eastern side of South America\"\n",
    "\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "token = word_tokenize(text.lower()); token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a3a4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 3, 'brazil': 2, 'on': 2, 'side': 2, 'of': 2, 'in': 1, 'they': 1, 'drive': 1, 'right-hand': 1, 'road': 1, ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdist = FreqDist(token); fdist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06c25a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3),\n",
       " ('brazil', 2),\n",
       " ('on', 2),\n",
       " ('side', 2),\n",
       " ('of', 2),\n",
       " ('in', 1),\n",
       " ('they', 1),\n",
       " ('drive', 1),\n",
       " ('right-hand', 1),\n",
       " ('road', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329897a1",
   "metadata": {},
   "source": [
    "Stemming - converting tokens to it's base form. more cruder way of removing suffix. Doesn't take linguistic approach so the base form might not have the meaning. It's generally fast as it doesn't have to look up ine the stored data dictonary.\n",
    "\n",
    "Lemmatization - Understands the context and convert Tokens to it's meaningful base form that has dictionary meaning. Might take time with a huge data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcce57c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'brazil',\n",
       " 'they',\n",
       " 'drive',\n",
       " 'on',\n",
       " 'the',\n",
       " 'right-hand',\n",
       " 'side',\n",
       " 'of',\n",
       " 'the']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stem = [PorterStemmer().stem(i) for i in token]; stem[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64e54e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'brazil',\n",
       " 'they',\n",
       " 'drive',\n",
       " 'on',\n",
       " 'the',\n",
       " 'right-hand',\n",
       " 'side',\n",
       " 'of',\n",
       " 'the',\n",
       " 'road',\n",
       " '.',\n",
       " 'brazil',\n",
       " 'ha',\n",
       " 'a',\n",
       " 'large',\n",
       " 'coastline',\n",
       " 'on',\n",
       " 'the',\n",
       " 'eastern',\n",
       " 'side',\n",
       " 'of',\n",
       " 'south',\n",
       " 'america']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "lemma = [WordNetLemmatizer().lemmatize(i) for i in token]; lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd95b2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\p192\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['brazil',\n",
       " 'drive',\n",
       " 'right-hand',\n",
       " 'side',\n",
       " 'road',\n",
       " '.',\n",
       " 'brazil',\n",
       " 'large',\n",
       " 'coastline',\n",
       " 'eastern',\n",
       " 'side',\n",
       " 'south',\n",
       " 'america']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "a = set(stopwords.words('english'))\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "[i for i in token if i not in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cbfdec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 'IN'),\n",
       " ('brazil', 'NN'),\n",
       " ('they', 'PRP'),\n",
       " ('drive', 'VBP'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('right-hand', 'JJ'),\n",
       " ('side', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('road', 'NN'),\n",
       " ('.', '.'),\n",
       " ('brazil', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('large', 'JJ'),\n",
       " ('coastline', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('eastern', 'JJ'),\n",
       " ('side', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('south', 'NN'),\n",
       " ('america', 'NN')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### pos-tag\n",
    "\n",
    "nltk.pos_tag(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "119effc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 'IN'),\n",
       " ('brazil', 'NN'),\n",
       " ('they', 'PRP'),\n",
       " ('drive', 'VBP'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('right-hand', 'JJ'),\n",
       " ('side', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('road', 'NN'),\n",
       " ('.', '.'),\n",
       " ('brazil', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('large', 'JJ'),\n",
       " ('coastline', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('eastern', 'JJ'),\n",
       " ('side', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('south', 'NN'),\n",
       " ('america', 'NN')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named Entity Recognization (NER) - Detecting named entities such as place name, person name, location etc.\n",
    "\n",
    "from nltk import ne_chunk\n",
    "\n",
    "x = nltk.pos_tag(token)\n",
    "x\n",
    "#ne_chunk(nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "553eeb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lexion based Analysis - no labelled data but sets of words/phrases or heuristics or predefined rules. It's based on set of lexical and syntactic features of the text where set of positive and negative words define the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "302f6dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a one of the best apps acording to a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pretty good version of the game for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a silly game and can be frustrating, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a terrific game on any pad. Hrs of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>this app is fricken stupid.it froze on the kin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Please add me!!!!! I need neighbors! Ginger101...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>love it!  this game. is awesome. wish it had m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>I love love love this app on my side of fashio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>This game is a rip off. Here is a list of thin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  Positive\n",
       "0      This is a one of the best apps acording to a b...         1\n",
       "1      This is a pretty good version of the game for ...         1\n",
       "2      this is a really cool game. there are a bunch ...         1\n",
       "3      This is a silly game and can be frustrating, b...         1\n",
       "4      This is a terrific game on any pad. Hrs of fun...         1\n",
       "...                                                  ...       ...\n",
       "19995  this app is fricken stupid.it froze on the kin...         0\n",
       "19996  Please add me!!!!! I need neighbors! Ginger101...         1\n",
       "19997  love it!  this game. is awesome. wish it had m...         1\n",
       "19998  I love love love this app on my side of fashio...         1\n",
       "19999  This game is a rip off. Here is a list of thin...         0\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/amazon.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c38f5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [one, best, apps, acording, bunch, people, agr...\n",
       "1        [pretty, good, version, game, free, lot, diffe...\n",
       "2        [really, cool, game, bunch, level, find, golde...\n",
       "3        [silly, game, frustrating, lot, fun, definitel...\n",
       "4        [terrific, game, pad, hr, fun, grandkids, love...\n",
       "                               ...                        \n",
       "19995    [app, fricken, stupid, froze, kindle, wont, al...\n",
       "19996    [please, add, need, neighbor, ginger1016, than...\n",
       "19997    [love, game, awesome, wish, free, stuff, house...\n",
       "19998    [love, love, love, app, side, fashion, story, ...\n",
       "19999    [game, rip, list, thing, make, better, bull, f...\n",
       "Name: reviewText, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "#df['reviewText'] = df['reviewText'].apply(lambda x: word_tokenize(x.lower()))\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: [i for i in x if i not in stopwords.words('english')])\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: [WordNetLemmatizer().lemmatize(i) for i in x])\n",
    "#df['reviewText'] = df['reviewText'].apply(lambda x: tokenizer.tokenize(x))\n",
    "df['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8e41d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one best apps acording bunch people agree bomb...\n",
       "1        pretty good version game free lot different le...\n",
       "2        really cool game bunch level find golden egg s...\n",
       "3        silly game frustrating lot fun definitely reco...\n",
       "4        terrific game pad hr fun grandkids love great ...\n",
       "                               ...                        \n",
       "19995    app fricken stupid froze kindle wont allow pla...\n",
       "19996    please add need neighbor ginger1016 thanks bun...\n",
       "19997    love game awesome wish free stuff house cost m...\n",
       "19998    love love love app side fashion story fight wo...\n",
       "19999    game rip list thing make better bull first nee...\n",
       "Name: reviewText_2, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewText_2'] = df['reviewText'].apply(lambda x: ' '.join(x)); df['reviewText_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba7c5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df57652c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "      <th>reviewText_2</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[one, best, apps, acording, bunch, people, agr...</td>\n",
       "      <td>1</td>\n",
       "      <td>one best apps acording bunch people agree bomb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[pretty, good, version, game, free, lot, diffe...</td>\n",
       "      <td>1</td>\n",
       "      <td>pretty good version game free lot different le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[really, cool, game, bunch, level, find, golde...</td>\n",
       "      <td>1</td>\n",
       "      <td>really cool game bunch level find golden egg s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[silly, game, frustrating, lot, fun, definitel...</td>\n",
       "      <td>1</td>\n",
       "      <td>silly game frustrating lot fun definitely reco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[terrific, game, pad, hr, fun, grandkids, love...</td>\n",
       "      <td>1</td>\n",
       "      <td>terrific game pad hr fun grandkids love great ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[app, fricken, stupid, froze, kindle, wont, al...</td>\n",
       "      <td>0</td>\n",
       "      <td>app fricken stupid froze kindle wont allow pla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[please, add, need, neighbor, ginger1016, than...</td>\n",
       "      <td>1</td>\n",
       "      <td>please add need neighbor ginger1016 thanks bun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[love, game, awesome, wish, free, stuff, house...</td>\n",
       "      <td>1</td>\n",
       "      <td>love game awesome wish free stuff house cost m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[love, love, love, app, side, fashion, story, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>love love love app side fashion story fight wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[game, rip, list, thing, make, better, bull, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>game rip list thing make better bull first nee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  Positive  \\\n",
       "0      [one, best, apps, acording, bunch, people, agr...         1   \n",
       "1      [pretty, good, version, game, free, lot, diffe...         1   \n",
       "2      [really, cool, game, bunch, level, find, golde...         1   \n",
       "3      [silly, game, frustrating, lot, fun, definitel...         1   \n",
       "4      [terrific, game, pad, hr, fun, grandkids, love...         1   \n",
       "...                                                  ...       ...   \n",
       "19995  [app, fricken, stupid, froze, kindle, wont, al...         0   \n",
       "19996  [please, add, need, neighbor, ginger1016, than...         1   \n",
       "19997  [love, game, awesome, wish, free, stuff, house...         1   \n",
       "19998  [love, love, love, app, side, fashion, story, ...         1   \n",
       "19999  [game, rip, list, thing, make, better, bull, f...         0   \n",
       "\n",
       "                                            reviewText_2  scores  \n",
       "0      one best apps acording bunch people agree bomb...       1  \n",
       "1      pretty good version game free lot different le...       1  \n",
       "2      really cool game bunch level find golden egg s...       1  \n",
       "3      silly game frustrating lot fun definitely reco...       1  \n",
       "4      terrific game pad hr fun grandkids love great ...       1  \n",
       "...                                                  ...     ...  \n",
       "19995  app fricken stupid froze kindle wont allow pla...       0  \n",
       "19996  please add need neighbor ginger1016 thanks bun...       1  \n",
       "19997  love game awesome wish free stuff house cost m...       1  \n",
       "19998  love love love app side fashion story fight wo...       1  \n",
       "19999  game rip list thing make better bull first nee...       1  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Sentiment Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyser(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    sentiment = 1 if scores['pos'] > 0 else 0\n",
    "    return sentiment\n",
    "\n",
    "# Apply this to out dataframe\n",
    "\n",
    "df['scores'] = df['reviewText_2'].apply(analyser); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5aac15b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1063  3704]\n",
      " [  536 14697]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.22      0.33      4767\n",
      "           1       0.80      0.96      0.87     15233\n",
      "\n",
      "    accuracy                           0.79     20000\n",
      "   macro avg       0.73      0.59      0.60     20000\n",
      "weighted avg       0.77      0.79      0.75     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(confusion_matrix(df['Positive'], df['scores']))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df['Positive'], df['scores']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b8fd3",
   "metadata": {},
   "source": [
    "### ML- Based\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ce00296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240f7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fc3ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvect = CountVectorizer()                               #countvectorizer model object\n",
    "countvect_2 = countvect.fit_transform(df['reviewText_2'])   #create sparse matrix of documents and vector counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ce1c7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>app</td>\n",
       "      <td>10879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>game</td>\n",
       "      <td>6899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>love</td>\n",
       "      <td>4302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6813</th>\n",
       "      <td>great</td>\n",
       "      <td>4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8850</th>\n",
       "      <td>like</td>\n",
       "      <td>4042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  counts\n",
       "1187      app   10879\n",
       "6415     game    6899\n",
       "9070     love    4302\n",
       "6813    great    4092\n",
       "8850     like    4042"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = countvect.get_feature_names_out() #features\n",
    "\n",
    "df_sparse = pd.DataFrame(countvect_2.todense(), columns = features)\n",
    "\n",
    "feature_counts = np.sum(df_sparse.values, axis = 0)\n",
    "\n",
    "feature_counts_df = pd.DataFrame(dict(features = features, counts = feature_counts))\n",
    "feature_counts_df.sort_values(by = 'counts', ascending=False, inplace = True); feature_counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff836b7a",
   "metadata": {},
   "source": [
    "### Naive - Bayes Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2243fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbddb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "624f8989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5325\n",
      "[[ 711  236]\n",
      " [1634 1419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.75      0.43       947\n",
      "           1       0.86      0.46      0.60      3053\n",
      "\n",
      "    accuracy                           0.53      4000\n",
      "   macro avg       0.58      0.61      0.52      4000\n",
      "weighted avg       0.73      0.53      0.56      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(countvect_2.todense(), df['Positive'], test_size=0.2, random_state=1)\n",
    "nb_clf = GaussianNB().fit(X_train, y_train)\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4392ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Not good let's tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "51a8fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import regex as re\n",
    "# Removing twitter handles, punctuation, extra spaces, numbers and special characters\n",
    "def remove_noise(text):\n",
    "# #      text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "# #                        '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', text)\n",
    "# #     text = ''.join([char if char not in string.punctuation else ' ' for char in text])\n",
    "#      text = re.sub(' +', ' ', text)\n",
    "#      text = re.sub('[0–9]+', '', text)\n",
    "#      text = re.sub('[^A-Za-z0–9_. ]+','',text) \n",
    "\n",
    "    text = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb2809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "bd25f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvect_tuned = CountVectorizer(stop_words='english', min_df=0.2, max_df=0.5, ngram_range=(1, 3)) \n",
    "\n",
    "#min_df - ignores tokens which are present in less than 20% documents.\n",
    "#max_df - ignores tokens which are present in more than 50% of the document.\n",
    "#max_features - limiting vocabulary size to 50. Selectly mots common 50 tokens.\n",
    "#binary - if set to False, then counts aren't taken only 1 and 0 are imputed.\n",
    "#processor = noise removal function etc.\n",
    "\n",
    "countvect_tuned_vector = countvect_tuned.fit_transform(df['reviewText_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de73ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "9775d954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>app</td>\n",
       "      <td>10879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>game</td>\n",
       "      <td>6899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>love</td>\n",
       "      <td>4302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>great</td>\n",
       "      <td>4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>like</td>\n",
       "      <td>4042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features  counts\n",
       "20       app   10879\n",
       "91      game    6899\n",
       "138     love    4302\n",
       "101    great    4092\n",
       "128     like    4042"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = countvect_tuned.get_feature_names() #features\n",
    "\n",
    "df_sparse = pd.DataFrame(countvect_tuned_vector.todense(), columns = features)\n",
    "\n",
    "feature_counts = np.sum(df_sparse.values, axis = 0)\n",
    "feature_counts_df = pd.DataFrame(dict(features = features, counts = feature_counts))\n",
    "feature_counts_df.sort_values(by = 'counts', ascending=False, inplace = True); feature_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3b7c9973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 254)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "cd577b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7453125\n",
      "Test accuracy: 0.74075\n",
      "[[ 820  127]\n",
      " [ 910 2143]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.87      0.61       947\n",
      "           1       0.94      0.70      0.81      3053\n",
      "\n",
      "    accuracy                           0.74      4000\n",
      "   macro avg       0.71      0.78      0.71      4000\n",
      "weighted avg       0.83      0.74      0.76      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(countvect_tuned_vector.todense(), df['Positive'], test_size=0.2, random_state=1)\n",
    "nb_clf = GaussianNB().fit(X_train, y_train)\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print('Train accuracy: {}'.format(accuracy_score(y_train, nb_clf.predict(X_train))))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test, y_pred)))\n",
    " \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8a573",
   "metadata": {},
   "source": [
    "### Tf-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f03d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "83dc6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer   \n",
    "idf_vect = TfidfVectorizer()                               #countvectorizer model object\n",
    "idf_vect_2 = idf_vect.fit_transform(df['reviewText_2']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "6b7e4bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>app</td>\n",
       "      <td>891.530160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>game</td>\n",
       "      <td>760.771047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>love</td>\n",
       "      <td>546.923368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6813</th>\n",
       "      <td>great</td>\n",
       "      <td>507.314671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8850</th>\n",
       "      <td>like</td>\n",
       "      <td>486.569063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features      counts\n",
       "1187      app  891.530160\n",
       "6415     game  760.771047\n",
       "9070     love  546.923368\n",
       "6813    great  507.314671\n",
       "8850     like  486.569063"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = idf_vect.get_feature_names() #features\n",
    "\n",
    "df_sparse = pd.DataFrame(idf_vect_2.todense(), columns = features)\n",
    "\n",
    "feature_counts = np.sum(df_sparse.values, axis = 0)\n",
    "\n",
    "feature_counts_df = pd.DataFrame(dict(features = features, counts = feature_counts))\n",
    "feature_counts_df.sort_values(by = 'counts', ascending=False, inplace = True); feature_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "6ba322c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7114375\n",
      "Test accuracy: 0.53125\n",
      "[[ 702  245]\n",
      " [1630 1423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.74      0.43       947\n",
      "           1       0.85      0.47      0.60      3053\n",
      "\n",
      "    accuracy                           0.53      4000\n",
      "   macro avg       0.58      0.60      0.52      4000\n",
      "weighted avg       0.72      0.53      0.56      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(idf_vect_2.todense(), df['Positive'], test_size=0.2, random_state=1)\n",
    "nb_clf = GaussianNB().fit(X_train, y_train)\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print('Train accuracy: {}'.format(accuracy_score(y_train, nb_clf.predict(X_train))))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test, y_pred)))\n",
    " \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf58e62c",
   "metadata": {},
   "source": [
    "### Tuned - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e172cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer   \n",
    "idf_vect = TfidfVectorizer(stop_words='english', min_df=0.01, max_df=.7, ngram_range=(1, 3))                            \n",
    "\n",
    "\n",
    "\n",
    "idf_vect_2 = idf_vect.fit_transform(df['reviewText_2']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "278e57c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7678125\n",
      "Test accuracy: 0.764\n",
      "[[ 813  134]\n",
      " [ 810 2243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.86      0.63       947\n",
      "           1       0.94      0.73      0.83      3053\n",
      "\n",
      "    accuracy                           0.76      4000\n",
      "   macro avg       0.72      0.80      0.73      4000\n",
      "weighted avg       0.84      0.76      0.78      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(idf_vect_2.todense(), df['Positive'], test_size=0.2, random_state=1)\n",
    "nb_clf = GaussianNB().fit(X_train, y_train)\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print('Train accuracy: {}'.format(accuracy_score(y_train, nb_clf.predict(X_train))))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test, y_pred)))\n",
    " \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9c233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c3d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72d785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
